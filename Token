from transformers import AutoTokenizer

# Specify the path to the local copy of bert-tiny
model_path = 'O:/ZRH/CF1/03 Projects/NNM Pipeline/bert-tiny'

# Initialize the tokenizer from the local directory
tokenizer = AutoTokenizer.from_pretrained(model_path)

# Tokenization of your datasets
def tokenize_function(examples):
    return tokenizer(examples, padding="max_length", truncation=True, max_length=128)

train_encodings = tokenize_function(list(train_texts))
val_encodings = tokenize_function(list(val_texts))
