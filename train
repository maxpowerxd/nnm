from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer
from transformers import AutoTokenizer
import numpy as np

# Specify the local model path
model_path = 'O:/ZRH/CF1/03 Projects/NNM Pipeline/bert-tiny'

# Load the model from the local directory
model = AutoModelForSequenceClassification.from_pretrained(model_path, num_labels=3)

# Assume tokenizer is defined similarly
tokenizer = AutoTokenizer.from_pretrained(model_path)

# Assuming test_texts and test_labels are ready
# Tokenize the test data
test_encodings = tokenizer(test_texts, truncation=True, padding=True, max_length=512)

# Convert to PyTorch tensors and create a dataset for the test data
test_dataset = CommentsDataset(test_encodings, list(test_labels))

# Define training arguments
training_args = TrainingArguments(
    output_dir='./results',          # directory to save the model and logging
    num_train_epochs=3,              # total number of training epochs
    per_device_train_batch_size=8,   # batch size per device during training
    per_device_eval_batch_size=16,   # batch size for evaluation
    warmup_steps=500,                # number of warmup steps for learning rate scheduler
    weight_decay=0.01,               # strength of weight decay regularization
    logging_dir='./logs',            # directory for storing logs
    logging_steps=10,                # log & save weights every logging_steps
    disable_tqdm=True,               # Disable tqdm progress bar to prevent Jupyter notebook conflicts
    evaluation_strategy="epoch"      # Evaluate at the end of each epoch
)

# Initialize the Trainer
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=val_dataset
)

# Start training
trainer.train()

# Evaluate the model on the test set
test_results = trainer.evaluate(test_dataset)

# Output the results of the test evaluation
print("Test Evaluation Results:", test_results)
