from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer

# Specify the local model path
model_path = 'O:/ZRH/CF1/03 Projects/NNM Pipeline/bert-tiny'

# Load the model from the local directory
model = AutoModelForSequenceClassification.from_pretrained(model_path, num_labels=3)

# Define training arguments
training_args = TrainingArguments(
    output_dir='./results',          # directory to save the model and logging
    num_train_epochs=3,              # total number of training epochs
    per_device_train_batch_size=8,   # batch size per device during training
    per_device_eval_batch_size=16,   # batch size for evaluation
    warmup_steps=500,                # number of warmup steps for learning rate scheduler
    weight_decay=0.01,               # strength of weight decay regularization
    logging_dir='./logs',            # directory for storing logs
    logging_steps=10,                # log & save weights every logging_steps
)

# Initialize the Trainer
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=val_dataset
)

# Start training
trainer.train()
