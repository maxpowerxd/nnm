from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer
from sklearn.model_selection import train_test_split

# Specify the local model path
model_path = 'O:/ZRH/CF1/03 Projects/NNM Pipeline/bert-tiny'

# Load the model from the local directory
model = AutoModelForSequenceClassification.from_pretrained(model_path, num_labels=3)

# Split the training data into training and validation sets
train_texts, val_texts, train_labels, val_labels = train_test_split(train_texts, train_labels, test_size=0.1, random_state=42)

# Define training arguments
training_args = TrainingArguments(
    output_dir='./results',          # directory to save the model and logging
    num_train_epochs=3,              # total number of training epochs
    per_device_train_batch_size=8,   # batch size per device during training
    per_device_eval_batch_size=16,   # batch size for evaluation
    warmup_steps=500,                # number of warmup steps for learning rate scheduler
    weight_decay=0.01,               # strength of weight decay regularization
    logging_dir='./logs',            # directory for storing logs
    logging_steps=10,                # log & save weights every logging_steps
    disable_tqdm=True                # Disable tqdm progress bar to prevent Jupyter notebook conflicts
)

# Initialize the Trainer
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=CommentsDataset(train_encodings, train_labels),
    eval_dataset=CommentsDataset(val_encodings, val_labels)
)

# Start training
trainer.train()

# Evaluate the model on the validation set
eval_results = trainer.evaluate()

# Print evaluation results
print(eval_results)
